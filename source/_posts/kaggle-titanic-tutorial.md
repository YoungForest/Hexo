---
title: kaggle入门之-titanic
categories:
  - kaggle
date: 2018-08-14 11:22:23
tags:
---


为了更快地锻炼自己数据挖掘的能力，我计划最近一个月花一定的时间在kaggle比赛上。目前的计划是把[Tutorial](https://www.kaggle.com/tags/tutorial)上的比赛、Datasets和牛人们的notebook跟完作为入门。之后再选择一个简单的常规比赛参加。
至于最后是否像欢哥一样走上数据挖掘竞赛之路，看入门之后的感受。自己是否愿意继续花大量的精力在上面。

数据挖掘的能力主要分为2部分：
- 机器学习
- 特征工程

之前在快手推荐组实习的时候，工作也涉及这些。推荐系统也算是数据挖掘的一个分支，从结果上看，是预测某个item是否会被用户点击。

[Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic)作为大多数人入门kaggle的第一步，确实是对数据挖掘技巧的集中体现。相反，最近在kaggle上比较火的比赛，都是和CV或NLP相关的。领域知识的要求更高，淡化了通用的数据挖掘技能。
在kaggle上还有许多[其他的教程](https://www.kaggle.com/tags/tutorial)可供用户学习，我今后会选择其中的一些进行重点学习，争取在开学前入门kaggle。

<!-- more -->
Titanic训练的技能为：
- 二分类(活/死)
- Python/R 基础

[notebook link](https://www.kaggle.com/helgejo/an-interactive-data-science-tutorial/notebook)这是我本次跟的notebook。
我把所有的代码都手敲了一遍，拒绝复制粘贴；该完成的Exercises也全部完成；对比赛的一般流程有了初步了解：

- 题目理解
- 数据理解
- 数据预处理
- 机器学习建模
- 模型评估
- 提交结果

## 题目理解

在问题描述中，一般会给出数据集的背景、每个challenge的目标、还有所需的技能。
还可以判断出需要哪些领域知识。比如在Titanic中，20世纪初 西方人的姓名、贵族爵位、船的相关知识都是极其有帮助的。

看完问题描述后，可以有自己基本的猜测：什么因素对是否存活影响最大？
我会想到 年龄和性别。媒体不是一直宣传沉船的时候，会让妇女儿童先走？
之后，我们会用数据分析的方式验证猜测是否合理。

## 数据理解

通过一些Python及其可视化的工具，我们可以快速对数据有初步的了解。

比如：`titanic`是存储所有原始数据的`pd.DataFrame`，`titanic.head()`可以显示最开始的5行，`titanic.describe()`显示所有特征的统计结果，包括最大值、最小值、缺失数量、均值方差等。
对所有原始特征有直观的了解后，可以知道，哪些特征是离散值，哪些是连续值，哪些需要预处理。

利用热力图，可以直观地看到不同特征之间的相关性。
对连续值，画出其分布图(`plot_distribution()`)；对离散值，画出箱形图(`plot_categories`).

通过这些技能，可以对**选择哪些特征进行建模**、**如何进行数据预处理** 心中有数。

## 数据预处理

对于离散值(Categorical variables)，需要将其转化为数值类型才能进行下一步的建模。
二类离散值可以简单地映射为(0, 1)，
多类离散值需要利用`pd.get_dummies()`进行one hot编码。

**对缺失值进行填充**。由于真实数据采集过程中的不确定性，有些行的某些列是缺失的，这时有2种选择：丢弃整个行，用有意义的值填充缺失值。
在数据比较宝贵的情况(数据量小 或 缺失值过多）下，一般采取填充的方式。对于离散值，可以填充“Unknown”；对于连续值，一般填充其均值。

**特征工程**。这是拉开不同选手之间水平的一项技能，需要一定的领域知识和对数据足够的敏感性。不过今年由于深度学习的原因，特征工程有被放弃的趋势。选手之前的差别主要靠调参。在Titanic中，如果你对20世纪初的西方足够了解的话，一些特征工程才能做。如，从姓名中提取出“Title”，是贵族、平民、还是职员。对船足够熟悉的话，可以从舱室提取出是几等舱，票号中提取出几等票。

**组装最后的数据集**。数据集经过我们的预处理后，需要进行特征选择，并组装成可以进行建模的形式。一般是一个`pd.DataFrame`，还需要切分成 训练集(Train)、验证集(Valid) 和 测试集(Test)。

## 建模 和 模型评估

这里也是大量工作所在。常用的机器学习模型要一个一个试，每个的参数也要进行调整后再试，然后用验证集评估，选出最好的。
很多时候，还需要回到数据预处理的部分，选择不同的特征，进行不同的特征工程，再回来进行建模和评估。

这部分属于枯燥的实验部分，因为需要大量的尝试和选择。当然，可以写自动化的脚本加速这些工作。

## 提交

提交比较简单。主要是需要注意提交的方法和格式。一般比赛都会给一个提交的模板，帮助参赛者理解所要求的格式。

我第一次提交因为预测值没有从浮点数转化为整数，分数只有0。之后解决这个问题后，获得了0.77033这样的分数，排名6242/9939。
这次提交算是对整个流程的一次体验。
我之后会继续特征工程和调参，以获得更高的分数。
牛逼的是有很多人满分，之前听说会有泄露预测信息到特征中的bug，不知道是不是这个原因。

## 后记

据今年找工作的师兄们和网络上的消息，今年算法工程师的岗位竞争十分激烈。很大程度是因为算法岗的高薪资，和去年毕业生尝到的甜头。大家纷纷从开发岗转去算法岗。众多数据挖掘的比赛也因此十分火爆，kaggle就是其中最火的一个比赛平台。我也打算花1个月时间蹭蹭热度，看看自己有没有做算法的天赋和能力。

在kaggle上，我首先关注了欢哥(mgchbot)，和大师兄(sparkingarthur)。看了他们的Profile，真是很厉害的人呐。尤其是欢哥，不愧是KDD的双料冠军。大师兄也不赖，平时在我面前特别谦虚（也可能是欢哥这样的人一直在身边吧）。他们的kaggle排名分别是100，和1000（现在共有超过8w人）。由于我还没有任何比赛结束，所以排名为Unranked。向优秀的人学习，因为有40w+户口的诱惑。